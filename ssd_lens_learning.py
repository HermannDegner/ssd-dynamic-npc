"""
SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - ã©ã†ã¶ã¤ã®æ£®NPCç”¨
æ§‹é€ ä¸»è¦³åŠ›å­¦ç†è«–ã«åŸºã¥ãè¨€èªãƒ¢ãƒ‡ãƒ«å­¦ç¿’

æ„å‘³åœ§ â†’ æ§‹é€ å¤‰åŒ– â†’ è¨€èªè¡¨ç¾ ã®å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import random
from transformers import AutoTokenizer, AutoModel

@dataclass
class SSDState:
    """SSDçŠ¶æ…‹ã®è¡¨ç¾"""
    # ç‰©ç†å±¤çŠ¶æ…‹
    weather: str = "sunny"
    temperature: float = 20.0
    time_period: str = "day"
    threat_level: float = 0.0
    
    # åŸºå±¤çŠ¶æ…‹
    comfort_level: float = 0.5
    social_fulfillment: float = 0.5
    exploration_need: float = 0.3
    creation_urge: float = 0.2
    recognition_level: float = 0.4
    
    # æ…£æ€§çŠ¶æ…‹
    habit_strength: Dict[str, float] = None
    memory_activation: Dict[str, float] = None
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    location: str = "village"
    player_present: bool = False
    other_npcs_present: List[str] = None
    
    def __post_init__(self):
        if self.habit_strength is None:
            self.habit_strength = {}
        if self.memory_activation is None:
            self.memory_activation = {}
        if self.other_npcs_present is None:
            self.other_npcs_present = []

@dataclass
class SSDResponse:
    """SSDå¿œç­”ã®è¡¨ç¾"""
    speech: str
    action: str
    emotion: str
    internal_state_change: Dict[str, float]
    memory_update: str

class SSDStateEncoder:
    """SSDçŠ¶æ…‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
    
    def __init__(self):
        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        self.weather_map = {"sunny": 0, "cloudy": 1, "rainy": 2, "stormy": 3}
        self.time_map = {"morning": 0, "day": 1, "evening": 2, "night": 3}
        self.location_map = {"village": 0, "home": 1, "beach": 2, "forest": 3, "shop": 4}
        self.action_map = {
            "greet": 0, "chat": 1, "explore": 2, "rest": 3, "work": 4,
            "exercise": 5, "create": 6, "seek_shelter": 7, "celebrate": 8
        }
        self.emotion_map = {
            "happy": 0, "sad": 1, "angry": 2, "calm": 3, "excited": 4,
            "anxious": 5, "friendly": 6, "lonely": 7, "confident": 8
        }
        
        self.vector_dim = 32  # çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
    
    def encode(self, state: SSDState) -> torch.Tensor:
        """SSDçŠ¶æ…‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
        vector = []
        
        # ç‰©ç†å±¤ (6æ¬¡å…ƒ)
        vector.append(self.weather_map.get(state.weather, 0) / 3.0)  # æ­£è¦åŒ–
        vector.append(state.temperature / 40.0)  # -20~40åº¦ã‚’0-1ã«
        vector.append(self.time_map.get(state.time_period, 1) / 3.0)
        vector.append(state.threat_level)
        vector.append(1.0 if state.player_present else 0.0)
        vector.append(len(state.other_npcs_present) / 5.0)  # æœ€å¤§5äººæƒ³å®š
        
        # åŸºå±¤çŠ¶æ…‹ (5æ¬¡å…ƒ)
        vector.extend([
            state.comfort_level,
            state.social_fulfillment,
            state.exploration_need,
            state.creation_urge,
            state.recognition_level
        ])
        
        # æ…£æ€§çŠ¶æ…‹ (10æ¬¡å…ƒ) - ä¸»è¦ãªç¿’æ…£ãƒ‘ã‚¿ãƒ¼ãƒ³
        common_habits = ["morning_routine", "social_chat", "creative_work", 
                        "exploration", "rest", "exercise", "cooking", "cleaning",
                        "shopping", "entertainment"]
        for habit in common_habits:
            vector.append(state.habit_strength.get(habit, 0.0))
        
        # è¨˜æ†¶æ´»æ€§åŒ– (10æ¬¡å…ƒ) - ä¸»è¦ãªè¨˜æ†¶ã‚«ãƒ†ã‚´ãƒª
        memory_categories = ["friendship", "achievement", "failure", "discovery",
                           "celebration", "conflict", "learning", "creation",
                           "seasonal", "special_event"]
        for category in memory_categories:
            vector.append(state.memory_activation.get(category, 0.0))
        
        # ä½ç½®æƒ…å ± (1æ¬¡å…ƒ)
        vector.append(self.location_map.get(state.location, 0) / 4.0)
        
        return torch.tensor(vector, dtype=torch.float32)
    
    def decode_action(self, action_idx: int) -> str:
        """è¡Œå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›"""
        action_list = list(self.action_map.keys())
        if 0 <= action_idx < len(action_list):
            return action_list[action_idx]
        return "unknown"
    
    def decode_emotion(self, emotion_idx: int) -> str:
        """æ„Ÿæƒ…ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›"""
        emotion_list = list(self.emotion_map.keys())
        if 0 <= emotion_idx < len(emotion_list):
            return emotion_list[emotion_idx]
        return "neutral"

class MeaningPressureCalculator(nn.Module):
    """æ„å‘³åœ§è¨ˆç®—å±¤"""
    
    def __init__(self, state_dim: int = 32):
        super().__init__()
        self.state_dim = state_dim
        
        # å„å±¤ã®æ„å‘³åœ§è¨ˆç®—
        self.physical_pressure = nn.Linear(6, 16)
        self.basal_pressure = nn.Linear(5, 16)  
        self.inertia_pressure = nn.Linear(21, 16)  # ç¿’æ…£10 + è¨˜æ†¶10 + ä½ç½®1
        
        # æ„å‘³åœ§çµ±åˆ
        self.pressure_integration = nn.Linear(48, 32)  # 16*3 = 48
        self.pressure_norm = nn.LayerNorm(32)
        
        self.activation = nn.GELU()
    
    def forward(self, state_vector: torch.Tensor) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:
        """æ„å‘³åœ§ã‚’è¨ˆç®—"""
        # çŠ¶æ…‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’å„å±¤ã«åˆ†å‰²
        physical = state_vector[:, :6]      # ç‰©ç†å±¤
        basal = state_vector[:, 6:11]       # åŸºå±¤
        inertia = state_vector[:, 11:]      # æ…£æ€§å±¤
        
        # å„å±¤ã®æ„å‘³åœ§è¨ˆç®—
        phys_pressure = self.activation(self.physical_pressure(physical))
        basal_pressure = self.activation(self.basal_pressure(basal))
        inertia_pressure = self.activation(self.inertia_pressure(inertia))
        
        # æ„å‘³åœ§çµ±åˆ
        combined_pressure = torch.cat([phys_pressure, basal_pressure, inertia_pressure], dim=-1)
        integrated_pressure = self.pressure_norm(self.pressure_integration(combined_pressure))
        
        pressure_components = {
            "physical": phys_pressure,
            "basal": basal_pressure, 
            "inertia": inertia_pressure,
            "integrated": integrated_pressure
        }
        
        return integrated_pressure, pressure_components

class StructuralChangePredictor(nn.Module):
    """æ§‹é€ å¤‰åŒ–äºˆæ¸¬å±¤"""
    
    def __init__(self, pressure_dim: int = 32, hidden_dim: int = 128):
        super().__init__()
        self.pressure_dim = pressure_dim
        self.hidden_dim = hidden_dim
        
        # æ§‹é€ å¤‰åŒ–äºˆæ¸¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
        self.change_predictor = nn.Sequential(
            nn.Linear(pressure_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, pressure_dim)
        )
        
        # è¡Œå‹•é¸æŠäºˆæ¸¬
        self.action_predictor = nn.Linear(pressure_dim, 9)  # 9ç¨®é¡ã®è¡Œå‹•
        
        # æ„Ÿæƒ…çŠ¶æ…‹äºˆæ¸¬
        self.emotion_predictor = nn.Linear(pressure_dim, 9)  # 9ç¨®é¡ã®æ„Ÿæƒ…
        
        # çŠ¶æ…‹å¤‰åŒ–ã®å¤§ãã•äºˆæ¸¬
        self.change_magnitude = nn.Linear(pressure_dim, 1)
        
    def forward(self, meaning_pressure: torch.Tensor) -> Dict[str, torch.Tensor]:
        """æ§‹é€ å¤‰åŒ–ã‚’äºˆæ¸¬"""
        # æ¬¡ã®çŠ¶æ…‹ã¸ã®å¤‰åŒ–ã‚’äºˆæ¸¬
        state_change = self.change_predictor(meaning_pressure)
        
        # è¡Œå‹•ãƒ»æ„Ÿæƒ…äºˆæ¸¬
        action_logits = self.action_predictor(meaning_pressure)
        emotion_logits = self.emotion_predictor(meaning_pressure)
        
        # å¤‰åŒ–ã®å¤§ãã•
        change_mag = torch.sigmoid(self.change_magnitude(meaning_pressure))
        
        return {
            "state_change": state_change,
            "action_logits": action_logits,
            "emotion_logits": emotion_logits,
            "change_magnitude": change_mag
        }

class SSDLanguageHead(nn.Module):
    """SSDè¨€èªç”Ÿæˆãƒ˜ãƒƒãƒ‰"""
    
    def __init__(self, ssd_dim: int = 32, vocab_size: int = 32000, max_length: int = 64):
        super().__init__()
        self.ssd_dim = ssd_dim
        self.vocab_size = vocab_size
        self.max_length = max_length
        
        # SSDçŠ¶æ…‹ã‚’è¨€èªç©ºé–“ã«ãƒãƒƒãƒ”ãƒ³ã‚°
        self.ssd_to_lang = nn.Linear(ssd_dim, 512)
        
        # è¨€èªç”Ÿæˆç”¨ã®Transformerãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=512,
            nhead=8,
            dim_feedforward=2048,
            dropout=0.1,
            batch_first=True
        )
        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)
        
        # å‡ºåŠ›å±¤
        self.output_projection = nn.Linear(512, vocab_size)
        
        # ä½ç½®åŸ‹ã‚è¾¼ã¿
        self.pos_embedding = nn.Embedding(max_length, 512)
        
    def forward(self, ssd_features: torch.Tensor, target_tokens: Optional[torch.Tensor] = None) -> torch.Tensor:
        """SSDç‰¹å¾´ã‹ã‚‰è¨€èªã‚’ç”Ÿæˆ"""
        batch_size = ssd_features.size(0)
        
        # SSDç‰¹å¾´ã‚’è¨€èªç©ºé–“ã«ãƒãƒƒãƒ”ãƒ³ã‚°
        lang_context = self.ssd_to_lang(ssd_features).unsqueeze(1)  # [batch, 1, 512]
        
        if target_tokens is not None:
            # è¨“ç·´æ™‚: æ•™å¸«ã‚ã‚Šã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
            seq_len = target_tokens.size(1)
            pos_ids = torch.arange(seq_len, device=target_tokens.device).unsqueeze(0).expand(batch_size, -1)
            pos_emb = self.pos_embedding(pos_ids)
            
            # ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            token_emb = torch.randn(batch_size, seq_len, 512, device=target_tokens.device)
            token_emb = token_emb + pos_emb
            
            # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å‡¦ç†
            output = self.transformer_decoder(token_emb, lang_context)
            logits = self.output_projection(output)
            
            return logits
        else:
            # æ¨è«–æ™‚: è‡ªå›å¸°ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
            generated = torch.zeros(batch_size, 1, 512, device=ssd_features.device)
            output = self.transformer_decoder(generated, lang_context)
            logits = self.output_projection(output)
            
            return logits

class SSDLensModel(nn.Module):
    """SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ã®çµ±åˆãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, vocab_size: int = 32000):
        super().__init__()
        
        # SSDçŠ¶æ…‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
        self.state_encoder = SSDStateEncoder()
        
        # æ„å‘³åœ§è¨ˆç®—
        self.meaning_pressure = MeaningPressureCalculator()
        
        # æ§‹é€ å¤‰åŒ–äºˆæ¸¬
        self.structure_predictor = StructuralChangePredictor()
        
        # è¨€èªç”Ÿæˆãƒ˜ãƒƒãƒ‰
        self.language_head = SSDLanguageHead(vocab_size=vocab_size)
        
        # æå¤±é–¢æ•°ã®é‡ã¿
        self.loss_weights = {
            "language": 1.0,
            "action": 0.5,
            "emotion": 0.5,
            "change": 0.3
        }
    
    def forward(self, ssd_state_batch: List[SSDState], 
                target_speech: Optional[torch.Tensor] = None,
                target_actions: Optional[torch.Tensor] = None,
                target_emotions: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """é †ä¼æ’­"""
        
        # SSDçŠ¶æ…‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        state_vectors = torch.stack([self.state_encoder.encode(state) for state in ssd_state_batch])
        
        # æ„å‘³åœ§è¨ˆç®—
        meaning_pressure, pressure_components = self.meaning_pressure(state_vectors)
        
        # æ§‹é€ å¤‰åŒ–äºˆæ¸¬
        structural_changes = self.structure_predictor(meaning_pressure)
        
        # è¨€èªç”Ÿæˆ
        if target_speech is not None:
            language_logits = self.language_head(meaning_pressure, target_speech)
        else:
            language_logits = self.language_head(meaning_pressure)
        
        outputs = {
            "language_logits": language_logits,
            "action_logits": structural_changes["action_logits"],
            "emotion_logits": structural_changes["emotion_logits"],
            "state_change": structural_changes["state_change"],
            "change_magnitude": structural_changes["change_magnitude"],
            "meaning_pressure": meaning_pressure,
            "pressure_components": pressure_components
        }
        
        return outputs
    
    def compute_loss(self, outputs: Dict[str, torch.Tensor],
                     targets: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ã®æå¤±è¨ˆç®—"""
        
        losses = {}
        
        # è¨€èªç”Ÿæˆæå¤±
        if "speech" in targets and outputs["language_logits"] is not None:
            language_loss = nn.CrossEntropyLoss()(
                outputs["language_logits"].reshape(-1, outputs["language_logits"].size(-1)),
                targets["speech"].reshape(-1)
            )
            losses["language"] = language_loss * self.loss_weights["language"]
        
        # è¡Œå‹•äºˆæ¸¬æå¤±
        if "action" in targets:
            action_loss = nn.CrossEntropyLoss()(outputs["action_logits"], targets["action"])
            losses["action"] = action_loss * self.loss_weights["action"]
        
        # æ„Ÿæƒ…äºˆæ¸¬æå¤±
        if "emotion" in targets:
            emotion_loss = nn.CrossEntropyLoss()(outputs["emotion_logits"], targets["emotion"])
            losses["emotion"] = emotion_loss * self.loss_weights["emotion"]
        
        # æ§‹é€ å¤‰åŒ–æå¤±ï¼ˆæ¬¡çŠ¶æ…‹äºˆæ¸¬ï¼‰
        if "next_state" in targets:
            change_loss = nn.MSELoss()(outputs["state_change"], targets["next_state"])
            losses["change"] = change_loss * self.loss_weights["change"]
        
        # ç·æå¤±
        total_loss = sum(losses.values())
        losses["total"] = total_loss
        
        return losses

class AnimalCrossingDataset(Dataset):
    """ã©ã†ã¶ã¤ã®æ£®é¢¨ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, data_size: int = 1000):
        self.data_size = data_size
        self.state_encoder = SSDStateEncoder()
        self.data = self._generate_synthetic_data()
    
    def _generate_synthetic_data(self) -> List[Dict]:
        """åˆæˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ"""
        data = []
        
        personalities = ["peppy", "lazy", "cranky", "normal", "jock", "snooty"]
        
        for i in range(self.data_size):
            personality = random.choice(personalities)
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªSSDçŠ¶æ…‹ç”Ÿæˆ
            state = self._generate_random_state(personality)
            
            # å¯¾å¿œã™ã‚‹å¿œç­”ç”Ÿæˆ
            response = self._generate_response_for_state(state, personality)
            
            data.append({
                "state": state,
                "response": response,
                "personality": personality
            })
        
        return data
    
    def _generate_random_state(self, personality: str) -> SSDState:
        """æ€§æ ¼ã«åŸºã¥ããƒ©ãƒ³ãƒ€ãƒ çŠ¶æ…‹ç”Ÿæˆ"""
        
        # æ€§æ ¼åˆ¥ã®å‚¾å‘
        personality_traits = {
            "peppy": {"social_fulfillment": 0.8, "exploration_need": 0.7},
            "lazy": {"comfort_level": 0.9, "creation_urge": 0.3},
            "cranky": {"comfort_level": 0.6, "recognition_level": 0.7},
            "normal": {"social_fulfillment": 0.6, "comfort_level": 0.6},
            "jock": {"exploration_need": 0.9, "recognition_level": 0.8},
            "snooty": {"recognition_level": 0.9, "creation_urge": 0.8}
        }
        
        base_traits = personality_traits.get(personality, {})
        
        state = SSDState(
            weather=random.choice(["sunny", "cloudy", "rainy", "stormy"]),
            temperature=random.uniform(-5, 35),
            time_period=random.choice(["morning", "day", "evening", "night"]),
            threat_level=random.uniform(0, 1) if random.random() < 0.2 else 0,
            
            comfort_level=base_traits.get("comfort_level", random.uniform(0.3, 0.8)),
            social_fulfillment=base_traits.get("social_fulfillment", random.uniform(0.2, 0.7)),
            exploration_need=base_traits.get("exploration_need", random.uniform(0.1, 0.6)),
            creation_urge=base_traits.get("creation_urge", random.uniform(0.1, 0.5)),
            recognition_level=base_traits.get("recognition_level", random.uniform(0.2, 0.6)),
            
            location=random.choice(["village", "home", "beach", "forest", "shop"]),
            player_present=random.choice([True, False]),
            other_npcs_present=random.choices(["alice", "bob", "charlie"], k=random.randint(0, 3))
        )
        
        return state
    
    def _generate_response_for_state(self, state: SSDState, personality: str) -> SSDResponse:
        """çŠ¶æ…‹ã«åŸºã¥ãå¿œç­”ç”Ÿæˆï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰"""
        
        # ç°¡æ˜“çš„ãªå¿œç­”ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
        if state.threat_level > 0.5:
            speech = "ã†ã‚ã‚ï¼å±é™ºãã†ï¼é¿é›£ã—ã¾ã—ã‚‡ã†ï¼"
            action = "seek_shelter"
            emotion = "anxious"
        elif state.player_present and state.social_fulfillment < 0.4:
            speech = "ã“ã‚“ã«ã¡ã¯ï¼ãŠè©±ã—ã—ã¾ã›ã‚“ã‹ï¼Ÿ"
            action = "greet"
            emotion = "friendly"
        elif state.exploration_need > 0.7:
            speech = "ä½•ã‹æ–°ã—ã„ã“ã¨ãŒã—ãŸã„ãªï¼"
            action = "explore"
            emotion = "excited"
        elif state.comfort_level < 0.3:
            speech = "ã¡ã‚‡ã£ã¨ç–²ã‚Œã¡ã‚ƒã£ãŸ..."
            action = "rest"
            emotion = "calm"
        else:
            speech = "ä»Šæ—¥ã‚‚ã„ã„å¤©æ°—ã§ã™ã­ï¼"
            action = "chat"
            emotion = "happy"
        
        return SSDResponse(
            speech=speech,
            action=action,
            emotion=emotion,
            internal_state_change={"comfort": 0.1},
            memory_update="daily_interaction"
        )
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        
        # ãƒ€ãƒŸãƒ¼ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ï¼ˆå®Ÿéš›ã«ã¯tokenizerã‚’ä½¿ç”¨ï¼‰
        speech_tokens = torch.randint(0, 1000, (20,))  # 20ãƒˆãƒ¼ã‚¯ãƒ³ã®å›ºå®šé•·
        
        return {
            "state": item["state"],
            "speech_tokens": speech_tokens,
            "action": self.state_encoder.action_map.get(item["response"].action, 0),
            "emotion": self.state_encoder.emotion_map.get(item["response"].emotion, 0),
            "personality": item["personality"]
        }

def train_ssd_lens_model():
    """SSDãƒ¬ãƒ³ã‚ºãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
    
    print("SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
    
    # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
    model = SSDLensModel(vocab_size=1000)  # ç°¡æ˜“çš„ãªèªå½™ã‚µã‚¤ã‚º
    optimizer = optim.AdamW(model.parameters(), lr=1e-4)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    dataset = AnimalCrossingDataset(data_size=1000)
    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)
    
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º: {len(dataset)}")
    print(f"ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")
    
    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    model.train()
    for epoch in range(10):  # ç°¡æ˜“çš„ã«10ã‚¨ãƒãƒƒã‚¯
        total_loss = 0
        num_batches = 0
        
        for batch in dataloader:
            optimizer.zero_grad()
            
            # å‰å‘ãè¨ˆç®—
            outputs = model(
                ssd_state_batch=batch["state"],
                target_speech=batch["speech_tokens"]
            )
            
            # æå¤±è¨ˆç®—
            targets = {
                "speech": batch["speech_tokens"],
                "action": batch["action"],
                "emotion": batch["emotion"]
            }
            
            losses = model.compute_loss(outputs, targets)
            
            # å¾Œå‘ãè¨ˆç®—
            losses["total"].backward()
            optimizer.step()
            
            total_loss += losses["total"].item()
            num_batches += 1
        
        avg_loss = total_loss / num_batches
        print(f"ã‚¨ãƒãƒƒã‚¯ {epoch+1}/10, å¹³å‡æå¤±: {avg_loss:.4f}")
    
    print("è¨“ç·´å®Œäº†ï¼")
    return model

def demo_ssd_lens_inference(model: SSDLensModel):
    """SSDãƒ¬ãƒ³ã‚ºæ¨è«–ã®ãƒ‡ãƒ¢"""
    
    print("\n=== SSDãƒ¬ãƒ³ã‚ºæ¨è«–ãƒ‡ãƒ¢ ===")
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: åµã®ä¸­ã®NPC
    test_state_1 = SSDState(
        weather="stormy",
        threat_level=0.8,
        comfort_level=0.2,
        player_present=True,
        location="village"
    )
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: ç¤¾äº¤çš„ãªNPC
    test_state_2 = SSDState(
        weather="sunny",
        social_fulfillment=0.3,
        exploration_need=0.7,
        player_present=True,
        location="beach"
    )
    
    test_cases = [
        ("åµã®çŠ¶æ³", test_state_1),
        ("ç¤¾äº¤çŠ¶æ³", test_state_2)
    ]
    
    model.eval()
    with torch.no_grad():
        for name, state in test_cases:
            print(f"\nã€{name}ã€‘")
            print(f"å…¥åŠ›çŠ¶æ…‹: å¤©å€™={state.weather}, è„…å¨={state.threat_level}, å¿«é©={state.comfort_level}")
            
            outputs = model([state])
            
            # è¡Œå‹•ãƒ»æ„Ÿæƒ…äºˆæ¸¬
            action_pred = torch.argmax(outputs["action_logits"], dim=-1)
            emotion_pred = torch.argmax(outputs["emotion_logits"], dim=-1)
            
            action_str = model.state_encoder.decode_action(action_pred.item())
            emotion_str = model.state_encoder.decode_emotion(emotion_pred.item())
            
            print(f"äºˆæ¸¬è¡Œå‹•: {action_str}")
            print(f"äºˆæ¸¬æ„Ÿæƒ…: {emotion_str}")
            print(f"æ„å‘³åœ§ã®å¼·ã•: {outputs['meaning_pressure'].norm().item():.3f}")

if __name__ == "__main__":
    print("ğŸŒŸ SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ  - ã©ã†ã¶ã¤ã®æ£®NPCç”¨ ğŸŒŸ")
    print("æ§‹é€ ä¸»è¦³åŠ›å­¦ã«åŸºã¥ãé©æ–°çš„è¨€èªãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("-" * 50)
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    trained_model = train_ssd_lens_model()
    
    # æ¨è«–ãƒ‡ãƒ¢
    demo_ssd_lens_inference(trained_model)
    
    print("\nâœ¨ SSDãƒ¬ãƒ³ã‚ºå­¦ç¿’ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—å®Œæˆï¼")
    print("ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯æ„å‘³åœ§ â†’ æ§‹é€ å¤‰åŒ– â†’ è¨€èªè¡¨ç¾ã®")
    print("æ–°ã—ã„å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚")
